{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Demo\n",
    "\n",
    "This is an early of UCSD's markdown to lecture pipeline through HeyGen. This pipeline takes you from a text document, or script, all the way to a finished video. The way it works is you edit a $\\verb|.md|$ found in the notebook scripts folder and feed the name to the second code cell in this notebook. An example and discussion of the syntax can be found in $\\verb|examples/example.md|$ or $\\verb|syntax.md|$. A list of voice and avatar ids is available in the files $\\verb|avatar_options/voices.txt|$ and $\\verb|avatar_options/avatars.txt|$.\n",
    "\n",
    "Supported syntax:\n",
    "\n",
    "    - Composition: can set position, scale, style, output_dim and background parameters within PIP format. \n",
    "\n",
    "        Ex: [type: pip, scale:0.5, position:(0.25;0.5)] This command will place the middle of the avatar in 25% of the way along the x dimension from the left, and halfway down from the top. It will be at half scale. The other parameters: style, output_dim and background will be set to defaults (normal, 1280x720 and #FFFFF respectively)\n",
    "        \n",
    "    - Transition: any transition including concatenation, any duration\n",
    "\n",
    "        Ex: {0.5, wipeleft} This will invoke a wipeleft transition that lasts 0.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that HeyGen seems to have caught on to my strategy of generating an arbitrary number of free trial api keys by using Apple's hide my email function. Calls from those APIs made with a jupyter notebook seem to take forever (I mean about 20 minutes) whereas on my laptop they take about 2 minutes. I need a non-trial APi key to keep doing this at scale. Keep that in mind when using the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the cell below before anything with ffmpeg. This is how you install ffmpeg on a binder notebook, thanks to [stack overflow](https://stackoverflow.com/questions/72217039/ffmpeg-and-jupyter-notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist = !which ffmpeg\n",
    "if not exist:\n",
    "  !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
    "     && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
    "  ffmdir = !find . -iname ffmpeg-*-static\n",
    "  path = %env PATH\n",
    "  path = path + ':' + ffmdir[0]\n",
    "  %env PATH $path\n",
    "print('')\n",
    "!which ffmpeg\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we're ready to get started. Enter the name of the file you wish to use below. I recommend using one of the files in the notebook_scripts folder. I will not being using those API keys so they are less likely to have hit their 5-clips-a-day limit. You can also use any file with your own API key if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./notebook_scripts/notebook_script5.md\" # \"./notebook_scripts/notebook_script1.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf *.mp4 *.jpg *.ass .\n",
    "! mkdir assets\n",
    "from parse import parse_from_file\n",
    "from upload import upload_script, parse_upload_response, get_slides, get_avatar_clips\n",
    "from compose import compose_scenes\n",
    "import sys\n",
    "import urllib.request\n",
    "from transition import transitions\n",
    "import ffmpeg\n",
    "import time\n",
    "\n",
    "script = parse_from_file(filepath)\n",
    "if script:\n",
    "    responses = upload_script(script)\n",
    "\n",
    "    # parse the response content into the scenes - literally just the avatar video ids\n",
    "    script = parse_upload_response(responses, script)\n",
    "\n",
    "    # get the slides \n",
    "    script = get_slides(script, \"./assets/\")\n",
    "\n",
    "    # then go get the links from the videos and download the clips. hopefully they've rendered by now\n",
    "    #time.sleep(1500)\n",
    "    script = get_avatar_clips(script, \"./assets/\")\n",
    "    print(script)\n",
    "\n",
    "    # compose the scenes\n",
    "    script = compose_scenes(script)\n",
    "    # transitions\n",
    "    (script, v, a, v_d, a_d) = transitions(script)\n",
    "    # output video\n",
    "    ffmpeg.output(v,a, script[0][\"Lecture Name\"]+\".mp4\", vcodec=\"h264\", pix_fmt='yuv420p', crf=18, preset=\"veryslow\", **{'b:a': '192k'}).run(overwrite_output=True)\n",
    "    \n",
    "    # presumably response has the URL of the pending video. for each of the clips get the url. for each one, download it.\n",
    "    # can't do this section without higher API limit yet\n",
    "    #print(responses)\n",
    "else:\n",
    "    print(script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
