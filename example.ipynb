{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Demo\n",
    "\n",
    "This is a really really basic demo of lecture script generation. The way it works is you edit the example.md found in the files tab and then run the following snippet. Please make sure to fill in the appropriate HeyGen API key at the very least"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the cell below before anything with ffmpeg. This is how you install ffmpeg on a binder notebook, thanks to [stack overflow](https://stackoverflow.com/questions/72217039/ffmpeg-and-jupyter-notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist = !which ffmpeg\n",
    "if not exist:\n",
    "  !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
    "     && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
    "  ffmdir = !find . -iname ffmpeg-*-static\n",
    "  path = %env PATH\n",
    "  path = path + ':' + ffmdir[0]\n",
    "  %env PATH $path\n",
    "print('')\n",
    "!which ffmpeg\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import parse_from_file\n",
    "from upload import upload_script, parse_upload_response, get_slides, get_avatar_clips\n",
    "from compose import compose_scenes\n",
    "import sys\n",
    "import urllib.request\n",
    "from transition import transitions\n",
    "import ffmpeg\n",
    "import time\n",
    "\n",
    "#filepath = sys.argv[1]\n",
    "\n",
    "#parsed = parse_from_file(filepath)\n",
    "#if parsed:\n",
    "#    response = upload_script(parsed)\n",
    "\n",
    "    # TODO combine the videos\n",
    "    # presumably response has the URL of the pending video. for each of the clips get the url. for each one, download it.\n",
    "    # can't do this section without higher API limit yet\n",
    "#    print(response)\n",
    "#else:\n",
    "#    print(parsed)\n",
    "\n",
    "\n",
    "### OUTLINE:\n",
    "\n",
    "# parse the text into scenes \n",
    "# scene object has porperties like\n",
    "# - number: what number in the sequence this is\n",
    "# - style: the type of composition: pip, avatar-only, side by side [for now], slide only\n",
    "#   - avatar_scale: how big the avatar is\n",
    "#   - slides_scale: how big the slide image is\n",
    "#   - avatar_position: where in the image the avatar is\n",
    "#   - slides_position: where in the image the slide image is\n",
    "# - slide:\n",
    "#   - slide_source_type: where the slide is coming from. for now just URL type\n",
    "#   - slide_url: where to get the slide image from\n",
    "#   - slide_img: the actual image\n",
    "# - background:\n",
    "#   - background_source_type: where the background is coming from URL and static background for now.\n",
    "#   - background_url: where to get the background from\n",
    "#   - background_command: how to generate the background if it's a command\n",
    "# - transition_in:\n",
    "#   - transition_type: for now only accept fade\n",
    "#   - tranisiton_duration: how long to make the transition\n",
    "# - avatar_video:\n",
    "#   - avatar_video_id: id for the video per heygen\n",
    "#   - avatar_video_url: the url for the video\n",
    "#   - avatar_ideo: the video itself\n",
    "#   - avatar_video_probe: the video data like stream length and such\n",
    "# - text: the text that is said in this clip\n",
    "# - clip: the composed clip pre-transition\n",
    "# - caption:\n",
    "#   - caption_url: duh\n",
    "#   - caption_filename: caption filename\n",
    "#   - parsed_caption: the caption info (start stamp, end stamp, text)\n",
    "\n",
    "# scripting markup: \n",
    "# - \\n means new clip\n",
    "# - \\\\ mid-clip change\n",
    "\n",
    "# the order of operations will be: \n",
    "# - parse script\n",
    "# - post to heygen and get the slides assets\n",
    "# - get the heygen videos from the ids\n",
    "# - compose the clips\n",
    "# - splice everything together\n",
    "\n",
    "# two types of transitions\n",
    "# - between_clips: that is,the video_id of this clip and the previous is different. \n",
    "# - mid_clip: the video_id of this clip and the previous is the same. we have to use caption information to sync them up. \n",
    "\n",
    "# I think with this we can do everything except for changing the slides halfway through the avatar clip in a side by side. \n",
    "# the problem is that that requires a transition before the composition has finished, and splitting it into two clips means that the avatar resets\n",
    "# it's ok if we make the transition methods available to the composition algorithm. we can specify that this is a special scene and follow a special order.\n",
    "\n",
    "\n",
    "# V\n",
    "filepath = \"FILE OF CHOICE\"\n",
    "\n",
    "script = parse_from_file(filepath)\n",
    "if script:\n",
    "    responses = upload_script(script)\n",
    "\n",
    "    # parse the response content into the scenes - literally just the avatar video ids\n",
    "    script = parse_upload_response(responses, script)\n",
    "\n",
    "    # get the slides \n",
    "    script = get_slides(script)\n",
    "\n",
    "    # then go get the links from the videos and download the clips. hopefully they've rendered by now\n",
    "    #time.sleep(1500)\n",
    "    script = get_avatar_clips(script)\n",
    "    print(script)\n",
    "\n",
    "    # compose the scenes\n",
    "    script = compose_scenes(script)\n",
    "    # transitions\n",
    "    (script, v, a, v_d, a_d) = transitions(script)\n",
    "    # output video\n",
    "    ffmpeg.output(v,a, script[0][\"Lecture Name\"]+\".mp4\", pix_fmt='yuv420p').run()\n",
    "    \n",
    "    # presumably response has the URL of the pending video. for each of the clips get the url. for each one, download it.\n",
    "    # can't do this section without higher API limit yet\n",
    "    #print(responses)\n",
    "else:\n",
    "    print(script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
