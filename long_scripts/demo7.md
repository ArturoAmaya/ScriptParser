Name: Arturo Amaya
Lecture Name: Lecture 10
HeyGen API key: OTk4ZGEzMmQ5M2ZkNGQzNmFiZTc3MjVlMWQ0NjAyZTgtMTcxMzU2MDQ0MA==
Default Composition: [type:pip]
Default Transition: {type: fade, duration: 1.0}
Default Avatar: (id:Luke_public_3_20240306, voice_id:5dddee02307b4f49a17c123c120a60ca, position:0.75;0.75, scale:0.5, style:closeUp, cbc:#453423, bc:#FFEE22)
Slides:
    https://drive.google.com/file/d/1FA1nbItrZQOkd9hq8QEczaLeo9mnOBgD/view?usp=sharing
    https://drive.google.com/file/d/1BJMAHgQpM7_OLUNCG5hUN5_JorYS1t2-/view?usp=sharing
    https://drive.google.com/file/d/1BJMAHgQpM7_OLUNCG5hUN5_JorYS1t2-/view?usp=sharing
    https://drive.google.com/file/d/1edZVRGxsK7OHeg5BRTp3uHKl1_xB_8BO/view?usp=sharing
    https://drive.google.com/file/d/1nxThwly38ZpnZkq-NjC6RhnzmmL_efaY/view?usp=sharing
--

(position:0.75;0.25, style:circle, cbc:#FFFFFF) So how big a cache is, we can measure how many cash blocks it has. If I just say, well, how many clash blocks does I have, sorry, what's the size of each cash block? Times the number of blocks? That's how big the cache is. Another way to think about it is how big is each block times the number of sets times the associativity. If you go back to the three dimensional picture. Number of sets times the associativity times the size of the block gives me the volume of this storage. Okay. When we talk about cash size, just make sure when we quote cash size, we're not talking about all the overhead bits. We're just talking about how much data can you store in it, not what the tag size is or stuff like that. Yeah. This one. A number Yes. So the block offset is the amount of bits needed to specify a byte within a block. So if the cash line is 64 bytes, then that would be six bits, bit zero through five.  Okay.

(position:0.8;0.8, scale:0.4) Here's a direct map cache. Again, it has two components, it has a data array and a tag array. These are just rams. A RAM typically is organized as a row decoder and a column decoder. It's a two dimensional usually. If you look at a chip, you take a bunch of ram cells, you lay them out in a grid, and you have a rood row of these am I accessing and then that row is access and then I have a mux at the bottom which selects which columns I want.  Okay. So this isn't that different? In this case, I have one column for the Tager and have a decoder, which says, which row A wants. So in this case, let's say, I have this cache where the cash line size is 16 bytes. So bits three through zero are the bite that I want within the cache. Why? Then the index would be if there's 256 rows, that's going to be the next eight bits 11 through four. Then the tag is everything else. I take an address. I throw it on top of this rubric here, and then I look at well, this address is ABCDE 043. I take these bits zero four and I send them to the decoder and I find four. Notice I send it to two decoders, one is in the tag array, one in data array logically.  Okay.

(position:0.8;0.8, scale:0.4) What's going to happen now is I'm going to access R four, I'm going to pull out this data, ABCD and a valid bit. I send that down to the comparative here and I compare it with tag 31 through 12. If its 31 to 12, ABCDE match what's coming out of the tag, it's a hit, and it's valid. I take the output as comparative and I end it with a valid bit. If the valid bit is zero, then I ignore what's stored in the tag it's not been initialized. That makes sense. That's how you hit or miss. If it's a hit, then I additionally take bits three through two here. Let's say that the array is outputting 16 bytes. Let's see. What is that? That's 32 bits, 64, says 128 bits. It says 128 bits wide, and it brings out 32 bits at a time. I have this four to one x which is xing different 32 bit values. I use bits three through two to select which word I want out of the cache. And then if you actually want to bite and stuff like that, usually that's done in the data path in a load of liner, you have to do sign extension on sine bytes and stuff like that. Does that make sense? That's the simplest cache direct map or one way set associative, isn't that way, think about it?  Okay. 

(position:0.6;0.85, scale:0.4) So if I want a set associative cache, It's the same idea, but now I've got the direct mapped cache, I've got a tag array and a data array, but I've got three of them. So it's a three way set associate of cache. And one cache set are all the cache lines that share the same index. So I do this purple box here. What I'm going to do is I'm going to look at all three tags at the same time. If any of them hit, I will control this x to select the data array of the cache way that hit. And if all of the miss, then I have a miss.  Okay. So the set is a set of addresses with identical index bits. The number of ways is the number of cash blocks I can store that have the same index. So if there's three way set associative, that means I can accommodate up to three cash blocks in my cash that all have the same index. Remember the one way set associative, each index had to be unique. Every cash block in there had to have a unique index. Three way set associative, I can have three cash blocks that have the same index and when I get the fourth one, then I have a problem.  Okay. And obviously, in a fully associated cache, this one set extends all the way out here, each tag array becomes trivially just one entry. So now I'm just doing a comparative for each entry. Does that make sense?  Okay.

All right. Let's do a clicker. Given a four kilobit two way sto cache with 32 bit line size and a 32 bit address, how many bits are needed for address in the tag array? Let's do this. ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“ðŸ•“