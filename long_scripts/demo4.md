Name: Arturo Amaya
Lecture Name: Lecture 10
HeyGen API key: OGNiYzgxM2JkMjVmNGIzZTlmOGU4NDU5OWI0NzJlNTctMTcxNzc5MjkxOA==
Default Composition: [type:pip]
Default Transition: {type: fade, duration: 1.0}
Default Avatar: (id:Luke_public_3_20240306, voice_id:5dddee02307b4f49a17c123c120a60ca, position:0.75;0.75, scale:0.5, style:closeUp, cbc:#453423, bc:#FFEE22)
Slides:
    https://drive.google.com/file/d/1pZ5s_DireDCRXAhPY5uEdyBtsjtvILQF/view?usp=share_link
    https://drive.google.com/file/d/1iqOxrnXnAeMbReZn5Tcl3w9d9YSSTXE5/view?usp=share_link
    https://drive.google.com/file/d/1VUEyeWw4O0U9dWbdHb6TDZFBAewjMkB9/view?usp=share_link
    https://drive.google.com/file/d/1CHcujQPv12B3BWdaiGvz953K11duldMJ/view?usp=share_link
    https://drive.google.com/file/d/15n-s-uFQ7Tv5yD1oBOQMm8qGPrvCqxN-/view?usp=share_link
--

(position:0.75;0.25, scale:0.5, style: circle, cbc: #FFFFFF) Okay. A friend of mine from HP made the slide for me a few years ago. He just tried to draw an analogy to distance. What are these hierarchies that we're dealing with? If you think about a register file, and let's say it's 1 nanosecond actually faster than that, let's say 1 nanosecond equates to 1 meter of distance. So your cache may be 10 nanoseconds, let's say ten times slower. It's maybe 10 meters away. Then our dram might be 100 times slower. Now 100 meters away. Our fabric de ram if you're talking about some uma system. Nowadays, we have things like C XL where the member is remote, maybe it's four times slower than regular dram. Maybe it's 400 meters away. Then this is when three D cross point was there. It was like 1,000 meters. It's going from here back to my office, maybe a little further. In terms of distance from 1 meter to 1,000 meters. If we talk about where is SSD, that's going from here to say Irvine. That's how much further away it is in time if time were distance. If we talk about hard disk drives, There are a lot further away, that's going from here to Boston. When your machines to read something from disc, it's significantly slower. How many know about taking operating system, know about paging, talked about paging and swapping? I know on an old computer that doesn't have enough memory, You'll see when you really start going and it's getting really slow, the disc is making crazy noises. That's because pages are moving in and out because you don't have enough memory, we'll talk about virtual memory. You don't have enough memory, it's swapping pages in and out from disc. But if each of those axises takes 5 million times longer than a normal access, that's really going to slow your machine now and that's why when you start running out of memory, machine gets really slow. It even happens on your laptop today. Programs just have a voracious appetite for memory and a lot of them have bugs where they leak memory and you start to run out of memory. 

(scale: 0.7) Okay. All right. Fundamentals, cash hit, cash, it times time hit ratio. Miss ratio. These are just terms we use. Hit means, what we're looking for is in the cache, and Miss means what we're looking for is not in the cache. Hit time is how long does it take to access the cache, and we got a hit. That was the latency I was talking about before. Four cycles for L one is latency. It's a hit time. Mis time is how long does it take to refill the cache and get the data I want. I missed in the L one, it goes out to main memory 100 cycles away. It takes me 100 cycles. To recover or 104 cycles, if you count the original four cycle miss. Hit ratio is just the number of hits over a number of axises. I count the number of times to access the cash, how many of those were hits. I want that to be a big number. This ratio is just one minus that number. These ratios can be deceiving because your performance your program really depends on how much time you spend waiting for memory. If your program only does four load instructions, and they all miss That probably doesn't matter. Or let's say your program did four load instruction, they all hit. It probably doesn't matter because you're doing so much other work that it doesn't matter if you 100% miss rate or 100% hit rate. When we're talking about evaluating, we'll talk about this a bit. The performance of member system, sometimes we just look at raw misses. Sometimes we like to look at something like what is the misses per thousand instructions? Because that takes into account how many load of stores I'm actually doing or this could be instruction misses, but basically, how many axes am I doing? Does it matter what my hit rate is. We'll look at some metrics like that later lecture.

(scale: 0.5) Okay. Okay, more terminology. Cash line size or cash block size is the basic unit that the cash deals in. We try to exploit spatial locality. By loading caches with a cache block. Instead of cashing just the thing we want, we cash some of the things around it, and that unit is called the cahline size or cash block size. We have different kinds of caches, instruction caches that hold only instructions, data caches of data and unified caches that can hold either one. We'll talk about these three, the misses Cold misses, which are also called compulsory, means they have to happen. Capacity misses happen because the cache isn't big enough, and then conflict misses happened because of the design of the cache. Because you're not able to put the data where you want to in the cache, you have to evict something. 

(scale: 0.5) Okay. So out of memory access, how do I know if something hits or misses in the cache? Or in a cache miss? Where do I put the new data? What data do I throw out? And how do I identify what these data are? So we'll talk about those.

(position:0.25;0.75, scale: 0.5) Okay. Here's a very simple cache. This cache has a box size of 16 bytes or four words, let's say a word is four bytes. He has two entries. It has this top row is one entry, and this bottom row is this entry. This is called the data array. This is where I'm going to store the cache data, the stuff I'm interested in. This is overhead, which is called the tag, and that's where I'm going to store the identifier that tells me what's in the cache. When I want to look in the cache to see if something's there or not, I'm going to look in the tag and it's going to tell me if the thing I want is either in this row or this row or this set or that set. Let's do an example and on the right, I've got main memory and I've divided it into here's the addresses going down the page. That's weird. I usually make addresses go the other way, but anyway, zero at the top, 60 at the bottom, and it's got data AEF, and I put these red lines here to mark what the cache blocks are in memory. If I take memory and divide it into blocks, that's what these red lines represent. Let's do our first access. 